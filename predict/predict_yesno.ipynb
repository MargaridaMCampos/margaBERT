{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "checkpoint_path = '../checkpoints/checkpoint_bio_yn_balanced_seed.pt'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_paths = [f'../preproc_datasets/8B_golden/8B{i}_golden.json' for i in range(1,6)]\n",
    "output_paths = [f'./predictions_yesno/8b_{i}_pred.csv' for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yn_predictions_csv(model_name,checkpoint_path, bioasq_test_path,output_path):    \n",
    "    \n",
    "    from transformers import BertForSequenceClassification\n",
    "    import torch\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels = 4)\n",
    "    checkpoint = torch.load(checkpoint_path,map_location=torch.device('cpu'))\n",
    "\n",
    "    from torch import nn\n",
    "    class BERT_Arch(nn.Module):\n",
    "\n",
    "        def __init__(self, model):\n",
    "\n",
    "            super(BERT_Arch, self).__init__()\n",
    "\n",
    "            self.model = model\n",
    "\n",
    "            # dropout layer\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "            # relu activation function\n",
    "            self.relu =  nn.ReLU()\n",
    "            # dense layer 1\n",
    "            self.fc1 = nn.Linear(4,512)\n",
    "\n",
    "            # dense layer 2 (Output layer)\n",
    "            self.fc2 = nn.Linear(512,2)\n",
    "            #softmax activation function\n",
    "            self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        #define the forward pass\n",
    "        def forward(self, input_ids,\n",
    "                attention_mask,\n",
    "                token_type_ids,labels):\n",
    "\n",
    "            #pass the inputs to the model  \n",
    "            outputs = self.model(input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,labels = labels)\n",
    "\n",
    "            cls_hs = outputs.logits\n",
    "\n",
    "            x = self.fc1(cls_hs)\n",
    "\n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # output layer\n",
    "            x = self.fc2(x)\n",
    "\n",
    "            # apply softmax activation\n",
    "            x = self.softmax(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    model_full = BERT_Arch(model)\n",
    "\n",
    "    checkpoint_model_dict = { k.replace('module.', ''): v for k, v in checkpoint['model_state_dict'].items()}\n",
    "\n",
    "    model_full.load_state_dict(checkpoint_model_dict)\n",
    "\n",
    "    from transformers import BertTokenizer\n",
    "    # Load the BERT tokenizer.\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name, \n",
    "                                              do_lower_case=True)\n",
    "\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    with open(bioasq_test_path, 'rb') as f:\n",
    "        bio_yn_raw = json.load(f)['questions']\n",
    "\n",
    "    bio_yn_raw = [question for question in bio_yn_raw if question['type'] == 'yesno']\n",
    "\n",
    "    bio_yn_questions = [question['body'] for question in bio_yn_raw]\n",
    "    bio_yn_ids = [question['id'] for question in bio_yn_raw]\n",
    "    bio_yn_labels = [question['exact_answer'] for question in bio_yn_raw]\n",
    "    bio_snippets = {question['id'] : [snippet['text'] \n",
    "                                      for snippet in question['snippets']] \n",
    "                    for question in bio_yn_raw}\n",
    "\n",
    "    ids = []\n",
    "    snippets = []\n",
    "    for key, value in bio_snippets.items():\n",
    "        for snippet in value:\n",
    "            ids.append(key)\n",
    "            snippets.append(snippet)\n",
    "\n",
    "    snippets_df = pd.DataFrame({'id': ids,'snippet': snippets})\n",
    "    questions_df = pd.DataFrame({'id': bio_yn_ids, \n",
    "                                 'question': bio_yn_questions,\n",
    "                                'label': bio_yn_labels})\n",
    "    val_df = pd.merge(snippets_df,questions_df, how = 'left', on = 'id')\n",
    "    val_a = list(val_df.question)\n",
    "    val_b = list(val_df.snippet)\n",
    "    val_labels = [int(answer == 'yes') for answer in val_df.label]\n",
    "\n",
    "    val_tokens = tokenizer(val_a,val_b, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=500,\n",
    "                           truncation=True, padding=True,return_tensors='pt')\n",
    "    val_tokens['labels'] = val_labels\n",
    "\n",
    "    val_predictions = []\n",
    "    for i in range(len(val_a)):    \n",
    "        inputs = tokenizer(val_a[i], val_b[i], \n",
    "                               add_special_tokens=True,\n",
    "                               max_length=500,\n",
    "                               truncation=True, padding=True,return_tensors='pt')\n",
    "        output = model_full(**inputs, labels = torch.tensor(val_tokens['labels'][i]))\n",
    "        pred = torch.argmax(output)\n",
    "        val_predictions.append(int(pred))\n",
    "\n",
    "    test_df = pd.DataFrame({'gold': val_labels,\n",
    "                           'pred': val_predictions})\n",
    "\n",
    "    test_df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
