{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAKE DATA\n",
    "pred = [np.random.randint(0,2) for i in range(100)]\n",
    "golden = [np.random.randint(0,2) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_yn(golden,pred):\n",
    "    \n",
    "    accuracy_score = metrics.accuracy_score(golden, pred)\n",
    "    print(f'Accuracy: {100 * round(accuracy_score,7)}%')\n",
    "    \n",
    "    f1_yes = metrics.f1_score(golden, pred, average = 'binary', pos_label=1)\n",
    "    print(f'F1_yes: {100 * round(f1_yes,7)}%')\n",
    "    \n",
    "    f1_no= metrics.f1_score(golden, pred, average = 'binary', pos_label=0)\n",
    "    print(f'F1_no: {100 * round(f1_no,7)}%')\n",
    "    \n",
    "    macro_f1 = metrics.f1_score(golden, pred, average = 'macro')\n",
    "    print(f'macroF1: {100 * round(macro_f1,7)}%')\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(golden, pred)\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    return accuracy_score, f1_yes, f1_no, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df = pd.DataFrame({'batch': [],\n",
    "                              'Acc': [],\n",
    "                              'F1_yes': [],\n",
    "                              'F1_no': [],\n",
    "                              'Macro_F1': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.7551%\n",
      "F1_yes: 92.96875%\n",
      "F1_no: 52.63158%\n",
      "macroF1: 72.80016%\n",
      "[[ 10  12]\n",
      " [  6 119]]\n",
      "Accuracy: 83.33333%\n",
      "F1_yes: 90.44944000000001%\n",
      "F1_no: 34.61538%\n",
      "macroF1: 62.532410000000006%\n",
      "[[ 18  38]\n",
      " [ 30 322]]\n",
      "Accuracy: 83.68056%\n",
      "F1_yes: 87.66404%\n",
      "F1_no: 75.89744%\n",
      "macroF1: 81.78074%\n",
      "[[ 74  30]\n",
      " [ 17 167]]\n",
      "Accuracy: 66.14583%\n",
      "F1_yes: 76.01476000000001%\n",
      "F1_no: 42.47788%\n",
      "macroF1: 59.24632%\n",
      "[[ 24  48]\n",
      " [ 17 103]]\n",
      "Accuracy: 63.87665%\n",
      "F1_yes: 65.83333%\n",
      "F1_no: 61.68224%\n",
      "macroF1: 63.75779%\n",
      "[[66 63]\n",
      " [19 79]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):    \n",
    "    test_df = pd.read_csv(f'../predict/predictions_yesno/8b_{i}_pred.csv')\n",
    "    test_metrics = [i] + list(get_metrics_yn(test_df.gold, test_df.pred))\n",
    "    all_metrics_df.loc[i] = test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1_yes</th>\n",
       "      <th>F1_no</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.728002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.904494</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.625324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.836806</td>\n",
       "      <td>0.876640</td>\n",
       "      <td>0.758974</td>\n",
       "      <td>0.817807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.760148</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.592463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.638767</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.637578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch       Acc    F1_yes     F1_no  Macro_F1\n",
       "1    1.0  0.877551  0.929688  0.526316  0.728002\n",
       "2    2.0  0.833333  0.904494  0.346154  0.625324\n",
       "3    3.0  0.836806  0.876640  0.758974  0.817807\n",
       "4    4.0  0.661458  0.760148  0.424779  0.592463\n",
       "5    5.0  0.638767  0.658333  0.616822  0.637578"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
