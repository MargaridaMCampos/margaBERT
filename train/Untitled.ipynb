{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: setuptools in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/margaridacampos/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.2, 1: 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (iterations on a dataset).\n",
       "\n",
       "Arguments:\n",
       "    x: Input data. It could be:\n",
       "      - A Numpy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "      - A TensorFlow tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "      - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "      - A `tf.data` dataset. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "      - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
       "        or `(inputs, targets, sample_weights)`.\n",
       "      A more detailed description of unpacking behavior for iterator types\n",
       "      (Dataset, generator, Sequence) is given below.\n",
       "    y: Target data. Like the input data `x`,\n",
       "      it could be either Numpy array(s) or TensorFlow tensor(s).\n",
       "      It should be consistent with `x` (you cannot have Numpy inputs and\n",
       "      tensor targets, or inversely). If `x` is a dataset, generator,\n",
       "      or `keras.utils.Sequence` instance, `y` should\n",
       "      not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided.\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        Note that the progress bar is not particularly useful when\n",
       "        logged to a file, so verbose=2 is recommended when not running\n",
       "        interactively (eg, in a production environment).\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `tf.keras.callbacks`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This argument is\n",
       "        not supported when `x` is a dataset, generator or\n",
       "       `keras.utils.Sequence` instance.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using `validation_split`\n",
       "        or `validation_data` is not affected by regularization layers like\n",
       "        noise and dropuout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_data` could be:\n",
       "          - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
       "          - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
       "          - dataset\n",
       "        For the first two cases, `batch_size` must be provided.\n",
       "        For the last case, `validation_steps` could be provided.\n",
       "        Note that `validation_data` does not support all the data types that\n",
       "        are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch'). This argument is ignored\n",
       "        when `x` is a generator. 'batch' is a special option for dealing\n",
       "        with the limitations of HDF5 data; it shuffles in batch-sized\n",
       "        chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample. This\n",
       "        argument is not supported when `x` is a dataset, generator, or\n",
       "       `keras.utils.Sequence` instance, instead provide the sample_weights\n",
       "        as the third element of `x`.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If x is a\n",
       "        `tf.data` dataset, and 'steps_per_epoch'\n",
       "        is None, the epoch will run until the input dataset is exhausted.\n",
       "        When passing an infinitely repeating dataset, you must specify the\n",
       "        `steps_per_epoch` argument. This argument is not supported with\n",
       "        array inputs.\n",
       "    validation_steps: Only relevant if `validation_data` is provided and\n",
       "        is a `tf.data` dataset. Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If 'validation_steps' is None, validation\n",
       "        will run until the `validation_data` dataset is exhausted. In the\n",
       "        case of an infinitely repeated dataset, it will run into an\n",
       "        infinite loop. If 'validation_steps' is specified and only part of\n",
       "        the dataset will be consumed, the evaluation will start from the\n",
       "        beginning of the dataset at each epoch. This ensures that the same\n",
       "        validation samples are used every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided. Integer\n",
       "        or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
       "        If an integer, specifies how many training epochs to run before a\n",
       "        new validation run is performed, e.g. `validation_freq=2` runs\n",
       "        validation every 2 epochs. If a Container, specifies the epochs on\n",
       "        which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
       "        validation at the end of the 1st, 2nd, and 10th epochs.\n",
       "    max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
       "        input only. Maximum size for the generator queue.\n",
       "        If unspecified, `max_queue_size` will default to 10.\n",
       "    workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "        only. Maximum number of processes to spin up\n",
       "        when using process-based threading. If unspecified, `workers`\n",
       "        will default to 1. If 0, will execute the generator on the main\n",
       "        thread.\n",
       "    use_multiprocessing: Boolean. Used for generator or\n",
       "        `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "        threading. If unspecified, `use_multiprocessing` will default to\n",
       "        `False`. Note that because this implementation relies on\n",
       "        multiprocessing, you should not pass non-picklable arguments to\n",
       "        the generator as they can't be passed easily to children processes.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass a tf.data.Dataset, generator, or\n",
       "  tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
       "  yield not only features (x) but optionally targets (y) and sample weights.\n",
       "  Keras requires that the output of such iterator-likes be unambiguous. The\n",
       "  iterator should return a tuple of length 1, 2, or 3, where the optional\n",
       "  second and third elements will be used for y and sample_weight\n",
       "  respectively. Any other type provided will be wrapped in a length one\n",
       "  tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
       "  should still adhere to the top-level tuple structure.\n",
       "  e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "  features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the namedtuple. The reason is that\n",
       "  it behaves like both an ordered datatype (tuple) and a mapping\n",
       "  datatype (dict). So given a namedtuple of the form:\n",
       "      `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "  it is ambiguous whether to reverse the order of the elements when\n",
       "  interpreting the value. Even worse is a tuple of the form:\n",
       "      `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "  where it is unclear if the tuple was intended to be unpacked into x, y,\n",
       "  and sample_weight or passed through as a single element to `x`. As a\n",
       "  result the data processing code will simply raise a ValueError if it\n",
       "  encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "Raises:\n",
       "    RuntimeError: 1. If the model was never compiled or,\n",
       "    2. If `model.fit` is  wrapped in `tf.function`.\n",
       "\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.Sequential()\n",
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
